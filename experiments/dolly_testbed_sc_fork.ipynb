{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Working with Dolly\n",
    "## Last Updated $DATE -  $AUTHOR.\n",
    "\n",
    "```\n",
    "Summary of High Level Research Question\n",
    "```\n",
    "\n",
    "Try to scope your experiments such you can answer your research question in 1-3 hours.\n",
    "This is an ideal time block to enter flow / deep work, but short enough that you will still feel \n",
    "motivated by a relatively tight feedback loop.\n",
    "\n",
    "If a problem seems like it needs more time that that, \n",
    "\n",
    "### High Level Experiment Design\n",
    "\n",
    "## Goals:\n",
    "```\n",
    "List of specific goals that this experiment seeks to achieve.\n",
    "\n",
    "This should fall under a few categories:\n",
    "- Development of Intuition about a _specific_ topic\n",
    "- Novel Research or Insight that could lead to a publishable result\n",
    "- Meaningfully explore a topic which could lead to an improvement in product\n",
    "\n",
    "Guiding principles should understanding, insight, and value creation.\n",
    "```\n",
    "\n",
    "## Tasks & Experiment Design\n",
    "\n",
    "```\n",
    "A list of specific tasks that are going to be tested \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "```\n",
    "Document high level research findings and how\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
      "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-06gql0_c\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-06gql0_c\n",
      "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 0ffcc8ad647d9e991f4c2596557a9d7475617773\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting jaxtyping>=0.2.11\n",
      "  Downloading jaxtyping-0.2.15-py3-none-any.whl (20 kB)\n",
      "Collecting datasets>=2.7.1\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (13.2.0)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (4.64.1)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.5.0)\n",
      "Requirement already satisfied: torch>=1.10 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.12.1+cu116)\n",
      "Collecting wandb>=0.13.5\n",
      "  Downloading wandb-0.15.1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.23.4)\n",
      "Collecting fancy-einsum>=0.0.3\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Collecting transformers>=4.25.1\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting einops>=0.6.0\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.28.2)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (10.0.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.13)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (5.4.1)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.12.0)\n",
      "Collecting typeguard>=2.13.3\n",
      "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.4.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.1.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (3.9.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.19.6)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.3)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.30)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.2)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (66.1.1)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (18.2.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.10)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2019.11.28)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.8)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.13.3->jaxtyping>=0.2.11->transformer-lens==0.0.0) (6.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.13.3->jaxtyping>=0.2.11->transformer-lens==0.0.0) (3.11.0)\n",
      "Building wheels for collected packages: transformer-lens\n",
      "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=89099 sha256=e9c4c1a436abe06007462feb506e9c233fd924e1ed72f98b6e58c637a50413aa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-phre7kfz/wheels/5f/16/e5/d9e9cc7a92784f4ab1b78c482598b8cc3ffed2b3eefe88045f\n",
      "Successfully built transformer-lens\n",
      "Installing collected packages: appdirs, fancy-einsum, einops, typeguard, wandb, transformers, jaxtyping, datasets, transformer-lens\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "Successfully installed appdirs-1.4.4 datasets-2.12.0 einops-0.6.1 fancy-einsum-0.0.3 jaxtyping-0.2.15 transformer-lens-0.0.0 transformers-4.28.1 typeguard-3.0.2 wandb-0.15.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting circuitsvis\n",
      "  Downloading circuitsvis-1.39.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m72.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.10 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.12.1+cu116)\n",
      "Collecting importlib-metadata<6.0.0,>=5.1.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.23.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0,>=1.10->circuitsvis) (4.4.0)\n",
      "Installing collected packages: importlib-metadata, circuitsvis\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed circuitsvis-1.39.1 importlib-metadata-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.14.1 tenacity-8.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install things into ENV\n",
    "# TODO: Setup up a container and push to docker that contains all these\n",
    "%pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
    "%pip install circuitsvis\n",
    "%pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic Set of Imports for MI Research\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup PyTorch configuration for inference based experiments\n",
    "# NOTE: Mark as False if you want to do any kind of training \n",
    "#       as part of your experimentation\n",
    "\n",
    "INFERENCE_ONLY_EXPERIMENT = True\n",
    "if INFERENCE_ONLY_EXPERIMENT:\n",
    "    torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-4e14dc73-c7a7\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-4e14dc73-c7a7\",\n",
       "      Hello,\n",
       "      {\"name\": \"Vivek\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f22a8201f40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Circuit Visualizations\n",
    "# TODO: Explore building out our own packages / tooling\n",
    "import circuitsvis as cv\n",
    "# Testing that the library works\n",
    "cv.examples.hello(\"Vivek\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf8f98dd7c847ea8d0457607dc37b25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "534e9409ef7343b7b2bcfabc11280300",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab9d4276f23e4c0799b3ae9fd68dec44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf2f639b163425da91003e59826cc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b219a28c2d24763b923531856fd0605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/13.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded hf_model, hooking transformer into TransformerLens!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7f15c11fa1c494787e5b2a1a568012e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformerConfig:\n",
      "{'act_fn': 'gelu',\n",
      " 'attention_dir': 'causal',\n",
      " 'attn_only': False,\n",
      " 'attn_types': None,\n",
      " 'checkpoint_index': None,\n",
      " 'checkpoint_label_type': None,\n",
      " 'checkpoint_value': None,\n",
      " 'd_head': 128,\n",
      " 'd_mlp': 16384,\n",
      " 'd_model': 4096,\n",
      " 'd_vocab': 50432,\n",
      " 'd_vocab_out': 50432,\n",
      " 'device': 'cuda',\n",
      " 'eps': 1e-05,\n",
      " 'final_rms': False,\n",
      " 'from_checkpoint': False,\n",
      " 'gated_mlp': False,\n",
      " 'init_mode': 'gpt2',\n",
      " 'init_weights': False,\n",
      " 'initializer_range': 0.0125,\n",
      " 'model_name': 'pythia-6.9b-deduped',\n",
      " 'n_ctx': 2048,\n",
      " 'n_devices': 1,\n",
      " 'n_heads': 32,\n",
      " 'n_layers': 32,\n",
      " 'n_params': 6442450944,\n",
      " 'normalization_type': 'LN',\n",
      " 'original_architecture': 'GPTNeoXForCausalLM',\n",
      " 'parallel_attn_mlp': True,\n",
      " 'positional_embedding_type': 'rotary',\n",
      " 'rotary_dim': 32,\n",
      " 'scale_attn_by_inverse_layer_idx': False,\n",
      " 'seed': None,\n",
      " 'tokenizer_name': 'EleutherAI/pythia-6.9b-deduped',\n",
      " 'use_attn_result': False,\n",
      " 'use_attn_scale': True,\n",
      " 'use_hook_tokens': False,\n",
      " 'use_local_attn': False,\n",
      " 'use_split_qkv_input': False,\n",
      " 'window_size': None}\n",
      "HookedTransformerConfig:\n",
      "{'act_fn': 'gelu',\n",
      " 'attention_dir': 'causal',\n",
      " 'attn_only': False,\n",
      " 'attn_types': None,\n",
      " 'checkpoint_index': None,\n",
      " 'checkpoint_label_type': None,\n",
      " 'checkpoint_value': None,\n",
      " 'd_head': 128,\n",
      " 'd_mlp': 16384,\n",
      " 'd_model': 4096,\n",
      " 'd_vocab': 50280,\n",
      " 'd_vocab_out': 50280,\n",
      " 'device': 'cuda',\n",
      " 'eps': 1e-05,\n",
      " 'final_rms': False,\n",
      " 'from_checkpoint': False,\n",
      " 'gated_mlp': False,\n",
      " 'init_mode': 'gpt2',\n",
      " 'init_weights': False,\n",
      " 'initializer_range': 0.0125,\n",
      " 'model_name': 'pythia-6.9b-deduped',\n",
      " 'n_ctx': 2048,\n",
      " 'n_devices': 1,\n",
      " 'n_heads': 32,\n",
      " 'n_layers': 32,\n",
      " 'n_params': 6442450944,\n",
      " 'normalization_type': 'LN',\n",
      " 'original_architecture': 'GPTNeoXForCausalLM',\n",
      " 'parallel_attn_mlp': True,\n",
      " 'positional_embedding_type': 'rotary',\n",
      " 'rotary_dim': 32,\n",
      " 'scale_attn_by_inverse_layer_idx': False,\n",
      " 'seed': None,\n",
      " 'tokenizer_name': 'EleutherAI/pythia-6.9b-deduped',\n",
      " 'use_attn_result': False,\n",
      " 'use_attn_scale': True,\n",
      " 'use_hook_tokens': False,\n",
      " 'use_local_attn': False,\n",
      " 'use_split_qkv_input': False,\n",
      " 'window_size': None}\n",
      "Loaded pretrained model into HookedTransformer!\n",
      "Model loss: tensor(4.5184, device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "# Load & Run a Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-7b\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-7b\")\n",
    "\n",
    "print(\"Loaded hf_model, hooking transformer into TransformerLens!\")\n",
    "# model = HookedTransformer.from_pretrained(\n",
    "#     \"EleutherAI/pythia-6.9b-deduped\",\n",
    "#     center_unembed=False,\n",
    "#     center_writing_weights=False,\n",
    "#     fold_ln=False,\n",
    "#     refactor_factored_attn_matrices=True,\n",
    "#     hf_model=hf_model\n",
    "# )\n",
    "\n",
    "### Janky Shit\n",
    "### TODO: Figure out how this library actually works and make this a cleaner integration.\n",
    "import transformer_lens.loading_from_pretrained as loading\n",
    "# Get the model name used in HuggingFace, rather than the alias.\n",
    "official_model_name = loading.get_official_model_name(\"EleutherAI/pythia-6.9b-deduped\")\n",
    "\n",
    "\n",
    "# Load the config into an HookedTransformerConfig object. If loading from a\n",
    "# checkpoint, the config object will contain the information about the\n",
    "# checkpoint\n",
    "cfg = loading.get_pretrained_model_config(\n",
    "    official_model_name,\n",
    "    checkpoint_index=None,\n",
    "    checkpoint_value=None,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    "    n_devices=1,\n",
    ")\n",
    "print(cfg)\n",
    "cfg.d_vocab = 50280\n",
    "cfg.d_vocab_out = 50280\n",
    "print(cfg)\n",
    "\n",
    "\n",
    "# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to match the HookedTransformer parameter names.\n",
    "state_dict = loading.get_pretrained_state_dict(\n",
    "    official_model_name, cfg, hf_model\n",
    ")\n",
    "\n",
    "# Create the HookedTransformer object\n",
    "model = HookedTransformer(cfg, tokenizer=tokenizer)\n",
    "\n",
    "model.load_and_process_state_dict(\n",
    "    state_dict,\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    move_state_dict_to_device=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded pretrained model into HookedTransformer!\")\n",
    "\n",
    "model_description_text = \"\"\"For this demo notebook we'll look at Dolly v2. It is based on pythia 6.9b, but we use the weights for dolly v2. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
    "# return_type of model can be loss, logits, both, or none!\n",
    "loss = model(model_description_text, return_type=\"loss\")\n",
    "print(\"Model loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HookedTransformerConfig:\n",
      "{'act_fn': 'gelu',\n",
      " 'attention_dir': 'causal',\n",
      " 'attn_only': False,\n",
      " 'attn_types': None,\n",
      " 'checkpoint_index': None,\n",
      " 'checkpoint_label_type': None,\n",
      " 'checkpoint_value': None,\n",
      " 'd_head': 128,\n",
      " 'd_mlp': 16384,\n",
      " 'd_model': 4096,\n",
      " 'd_vocab': 50280,\n",
      " 'd_vocab_out': 50280,\n",
      " 'device': 'cuda',\n",
      " 'eps': 1e-05,\n",
      " 'final_rms': False,\n",
      " 'from_checkpoint': False,\n",
      " 'gated_mlp': False,\n",
      " 'init_mode': 'gpt2',\n",
      " 'init_weights': False,\n",
      " 'initializer_range': 0.0125,\n",
      " 'model_name': 'pythia-6.9b-deduped',\n",
      " 'n_ctx': 2048,\n",
      " 'n_devices': 1,\n",
      " 'n_heads': 32,\n",
      " 'n_layers': 32,\n",
      " 'n_params': 6442450944,\n",
      " 'normalization_type': 'LN',\n",
      " 'original_architecture': 'GPTNeoXForCausalLM',\n",
      " 'parallel_attn_mlp': True,\n",
      " 'positional_embedding_type': 'rotary',\n",
      " 'rotary_dim': 32,\n",
      " 'scale_attn_by_inverse_layer_idx': False,\n",
      " 'seed': None,\n",
      " 'tokenizer_name': 'EleutherAI/pythia-6.9b-deduped',\n",
      " 'use_attn_result': False,\n",
      " 'use_attn_scale': True,\n",
      " 'use_hook_tokens': False,\n",
      " 'use_local_attn': False,\n",
      " 'use_split_qkv_input': False,\n",
      " 'window_size': None}\n"
     ]
    }
   ],
   "source": [
    "# DOLLY V2 - 7B Config\n",
    "pprint(model.cfg)\n",
    "\n",
    "# Transformer Lens Note:\n",
    "# get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token\n",
    "# are all methods that are added to the model object by TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
      "  Cloning https://github.com/neelnanda-io/Easy-Transformer.git (to revision clean-transformer-demo) to /tmp/pip-req-build-gdr7azw_\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/Easy-Transformer.git /tmp/pip-req-build-gdr7azw_\n",
      "  Running command git checkout -b clean-transformer-demo --track origin/clean-transformer-demo\n",
      "  Switched to a new branch 'clean-transformer-demo'\n",
      "  Branch 'clean-transformer-demo' set up to track remote branch 'clean-transformer-demo' from 'origin'.\n",
      "  Resolved https://github.com/neelnanda-io/Easy-Transformer.git to commit 1f25219e631aeb478d17075d47274db32c874e88\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (0.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (1.23.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (1.12.1+cu116)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (2.12.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (4.28.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (4.64.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (1.5.0)\n",
      "Requirement already satisfied: wandb in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (0.15.1)\n",
      "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.9/dist-packages (from easy-transformer==0.1.0) (0.0.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (23.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (0.18.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (2.28.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (0.70.13)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (3.8.3)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (0.12.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (2023.1.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (10.0.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (0.3.5.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets->easy-transformer==0.1.0) (5.4.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->easy-transformer==0.1.0) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->easy-transformer==0.1.0) (2022.7.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->easy-transformer==0.1.0) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->easy-transformer==0.1.0) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->easy-transformer==0.1.0) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->easy-transformer==0.1.0) (2022.10.31)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (8.1.3)\n",
      "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (1.4.4)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (3.19.6)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (0.4.0)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (66.1.1)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (1.3.2)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (3.1.30)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (5.9.4)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb->easy-transformer==0.1.0) (0.1.2)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb->easy-transformer==0.1.0) (1.14.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.3.3)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (2.1.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->easy-transformer==0.1.0) (6.0.4)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (4.0.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->easy-transformer==0.1.0) (2019.11.28)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->easy-transformer==0.1.0) (5.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "\n",
      "## Installing the NodeSource Node.js 16.x repo...\n",
      "\n",
      "\n",
      "## Populating apt-get cache...\n",
      "\n",
      "+ apt-get update\n",
      "Hit:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal InRelease                         \n",
      "Hit:3 http://security.ubuntu.com/ubuntu focal-security InRelease               \n",
      "Hit:4 http://archive.ubuntu.com/ubuntu focal-updates InRelease      \n",
      "Hit:5 http://archive.ubuntu.com/ubuntu focal-backports InRelease    \n",
      "Hit:6 https://deb.nodesource.com/node_16.x focal InRelease\n",
      "Hit:7 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Reading package lists... Done\n",
      "\n",
      "## Confirming \"focal\" is supported...\n",
      "\n",
      "+ curl -sLf -o /dev/null 'https://deb.nodesource.com/node_16.x/dists/focal/Release'\n",
      "\n",
      "## Adding the NodeSource signing key to your keyring...\n",
      "\n",
      "+ curl -s https://deb.nodesource.com/gpgkey/nodesource.gpg.key | gpg --dearmor | tee /usr/share/keyrings/nodesource.gpg >/dev/null\n",
      "\n",
      "## Creating apt sources list file for the NodeSource Node.js 16.x repo...\n",
      "\n",
      "+ echo 'deb [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' > /etc/apt/sources.list.d/nodesource.list\n",
      "+ echo 'deb-src [signed-by=/usr/share/keyrings/nodesource.gpg] https://deb.nodesource.com/node_16.x focal main' >> /etc/apt/sources.list.d/nodesource.list\n",
      "\n",
      "## Running `apt-get update` for you...\n",
      "\n",
      "+ apt-get update\n",
      "Hit:1 http://archive.ubuntu.com/ubuntu focal InRelease\n",
      "Hit:2 http://archive.ubuntu.com/ubuntu focal-updates InRelease\n",
      "Hit:3 http://archive.ubuntu.com/ubuntu focal-backports InRelease\n",
      "Hit:4 http://security.ubuntu.com/ubuntu focal-security InRelease\n",
      "Hit:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
      "Hit:6 https://deb.nodesource.com/node_16.x focal InRelease\n",
      "Hit:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease\n",
      "Reading package lists... Done\n",
      "\n",
      "## Run `\u001b[1msudo apt-get install -y nodejs\u001b[m` to install Node.js 16.x and npm\n",
      "## You may also need development tools to build native addons:\n",
      "     sudo apt-get install gcc g++ make\n",
      "## To install the Yarn package manager, run:\n",
      "     curl -sL https://dl.yarnpkg.com/debian/pubkey.gpg | gpg --dearmor | sudo tee /usr/share/keyrings/yarnkey.gpg >/dev/null\n",
      "     echo \"deb [signed-by=/usr/share/keyrings/yarnkey.gpg] https://dl.yarnpkg.com/debian stable main\" | sudo tee /etc/apt/sources.list.d/yarn.list\n",
      "     sudo apt-get update && sudo apt-get install yarn\n",
      "\n",
      "\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "nodejs is already the newest version (16.20.0-deb-1nodesource1).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 73 not upgraded.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Collecting git+https://github.com/neelnanda-io/PySvelte.git\n",
      "  Cloning https://github.com/neelnanda-io/PySvelte.git to /tmp/pip-req-build-173ngxnl\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/PySvelte.git /tmp/pip-req-build-173ngxnl\n",
      "  Resolved https://github.com/neelnanda-io/PySvelte.git to commit 6f5d971a148d40fb7481d400ae74551b37340e83\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (0.6.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (1.23.4)\n",
      "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (1.12.1+cu116)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (2.12.0)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (4.28.1)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (4.64.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (1.5.0)\n",
      "Requirement already satisfied: typeguard~=2.0 in /usr/local/lib/python3.9/dist-packages (from PySvelte==1.0.0) (2.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (5.4.1)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (0.3.5.1)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (0.70.13)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (2023.1.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (3.2.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (3.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (23.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (0.12.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (2.28.2)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets->PySvelte==1.0.0) (10.0.1)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->PySvelte==1.0.0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->PySvelte==1.0.0) (2.8.2)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->PySvelte==1.0.0) (4.4.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers->PySvelte==1.0.0) (2022.10.31)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers->PySvelte==1.0.0) (0.12.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers->PySvelte==1.0.0) (3.9.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (2.1.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (4.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets->PySvelte==1.0.0) (1.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->PySvelte==1.0.0) (1.14.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2.8)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets->PySvelte==1.0.0) (2019.11.28)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: fancy_einsum in /usr/local/lib/python3.9/dist-packages (0.0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: einops in /usr/local/lib/python3.9/dist-packages (0.6.1)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: datasets in /usr/local/lib/python3.9/dist-packages (2.12.0)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (2.28.2)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.3.5.1)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (4.64.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets) (3.2.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from datasets) (1.23.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (10.0.1)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from datasets) (1.5.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.12.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets) (0.70.13)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (5.4.1)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets) (2023.1.0)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets) (0.18.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets) (3.8.3)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets) (23.0)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.8.2)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (18.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.4.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.9.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets) (2019.11.28)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.14.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: transformers in /usr/local/lib/python3.9/dist-packages (4.28.1)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (1.23.4)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (0.12.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers) (2.28.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers) (2022.10.31)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->transformers) (2.8)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'easy_transformer.utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb Cell 10\u001b[0m in \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmath\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39measy_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m EasyTransformer\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39measy_transformer\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m get_corner, gelu_new, tokenize_and_concatenate\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X21sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mauto\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtqdm\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X21sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m dataset \u001b[39m=\u001b[39m datasets\u001b[39m.\u001b[39mload_dataset(\u001b[39m\"\u001b[39m\u001b[39mNeelNanda/pile-10k\u001b[39m\u001b[39m\"\u001b[39m, split\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'easy_transformer.utils'"
     ]
    }
   ],
   "source": [
    "\n",
    "%pip install git+https://github.com/neelnanda-io/Easy-Transformer.git@clean-transformer-demo\n",
    "  # Install another version of node that makes PySvelte work way faster\n",
    "!curl -fsSL https://deb.nodesource.com/setup_16.x | sudo -E bash -; sudo apt-get install -y nodejs  \n",
    "%pip install git+https://github.com/neelnanda-io/PySvelte.git\n",
    "%pip install fancy_einsum\n",
    "%pip install einops\n",
    "%pip install datasets\n",
    "%pip install transformers\n",
    "import datasets\n",
    "import transformers\n",
    "import plotly.express as px\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import math\n",
    "from easy_transformer import EasyTransformer\n",
    "from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n",
    "import tqdm.auto as tqdm\n",
    "dataset = datasets.load_dataset(\"NeelNanda/pile-10k\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_corner' from 'easy_transformer' (/notebooks/easy_transformer/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb Cell 11\u001b[0m in \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X22sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39measy_transformer\u001b[39;00m \u001b[39mimport\u001b[39;00m get_corner, gelu_new, tokenize_and_concatenate\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_corner' from 'easy_transformer' (/notebooks/easy_transformer/__init__.py)"
     ]
    }
   ],
   "source": [
    "#from easy_transformer.utils import get_corner, gelu_new, tokenize_and_concatenate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'On', ' hall', 'ow', 'een', ',', ' all', ' the', ' children', ' go', ' T', 'rick', ' or']\n",
      "tensor([[   0, 2374, 7423,  319, 9673,   13,  512,  253, 2151,  564,  308, 4662,\n",
      "          390]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c6244abbd7c43ac9dfa9ab0abc49cab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done one\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'EasyTransformer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb Cell 12\u001b[0m in \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m \u001b[39m#print(dataset)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m#print(dataset[0]['text'][:100])\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mEasyTransformer\u001b[39;00m \u001b[39mimport\u001b[39;00m easy_transformer \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m tokens_dataset \u001b[39m=\u001b[39m easy_transformer\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mtokenize_and_concatenate(dataset, model\u001b[39m.\u001b[39mtokenizer, streaming\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, max_length\u001b[39m=\u001b[39mmodel_cfg\u001b[39m.\u001b[39mn_ctx, column_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtext\u001b[39m\u001b[39m\"\u001b[39m, add_bos_token\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_proc\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/stephencohenfresh/Downloads/mi_research/experiments/dolly_testbed_sc_fork.ipynb#X12sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m data_loader \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mdata\u001b[39m.\u001b[39mDataLoader(tokens_dataset, batch_size\u001b[39m=\u001b[39mbatch_size, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m, pin_memory\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'EasyTransformer'"
     ]
    }
   ],
   "source": [
    "sample_string = \"On halloween, all the children go Trick or\"\n",
    "\n",
    "print(model.to_str_tokens(sample_string)) # Shows tokenization split\n",
    "print(model.to_tokens(sample_string)) #converts string to integer labeled tokens and then returns a tensor on models device of shape (batch, position)\n",
    "# NOTE: in GPT2, 50256 is the token for EOS, BOS, and Padding.\n",
    "# To single token converts string to a single integer, useful for looking up logits\n",
    "# to_string converts a tensor of tokens to a string\n",
    "\n",
    "\n",
    "#model.blocks.register_forward_hook  \n",
    "\n",
    "\n",
    "\n",
    "model.generate(sample_string,\n",
    "               temperature=0,\n",
    "               max_new_tokens=1)\n",
    "\n",
    "\n",
    "\n",
    "from pprint import pprint\n",
    "batch_size = 8\n",
    "num_epochs = 1\n",
    "max_steps = 1\n",
    "log_every = 1\n",
    "lr = 1e-3\n",
    "weight_decay = 1e-2\n",
    "overfitMax=1\n",
    "#model_cfg = Config(debug=False, d_model=256, n_heads=4, d_head=64, d_mlp=1024, n_layers=2, n_ctx=256, d_vocab=reference_gpt2.cfg.d_vocab)\n",
    "\n",
    "\n",
    "optimizer_copy = torch.optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "\n",
    "\n",
    "print(\"done one\")\n",
    "losses = []\n",
    "\n",
    "#print(dataset)\n",
    "#print(dataset[0]['text'][:100])\n",
    "from EasyTransformer import easy_transformer \n",
    "tokens_dataset = easy_transformer.utils.tokenize_and_concatenate(dataset, model.tokenizer, streaming=False, max_length=model_cfg.n_ctx, column_name=\"text\", add_bos_token=True, num_proc=4)\n",
    "data_loader = torch.utils.data.DataLoader(tokens_dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "print(\"Number of batches:\", len(data_loader))\n",
    "#test_string_trained = \"Hello world this is a test of overfitting\"\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'the', ' founder', ' of', ' Facebook', ' is', ' Mark']\n",
      "Tokenized answer: [' Z', 'ucker', 'berg']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.91</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.94</span><span style=\"font-weight: bold\">% Token: | Z|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m22.91\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m99.94\u001b[0m\u001b[1m% Token: | Z|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 22.91 Prob: 99.94% Token: | Z|\n",
      "Top 1th token. Logit: 15.02 Prob:  0.04% Token: | z|\n",
      "Top 2th token. Logit: 12.46 Prob:  0.00% Token: | E|\n",
      "Top 3th token. Logit: 12.16 Prob:  0.00% Token: | Elliot|\n",
      "Top 4th token. Logit: 11.97 Prob:  0.00% Token: |\n",
      "|\n",
      "Top 5th token. Logit: 11.81 Prob:  0.00% Token: | Cuban|\n",
      "Top 6th token. Logit: 11.52 Prob:  0.00% Token: |Z|\n",
      "Top 7th token. Logit: 11.40 Prob:  0.00% Token: |  |\n",
      "Top 8th token. Logit: 10.68 Prob:  0.00% Token: |us|\n",
      "Top 9th token. Logit: 10.56 Prob:  0.00% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.77</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.60</span><span style=\"font-weight: bold\">% Token: |ucker|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m23.77\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m99.60\u001b[0m\u001b[1m% Token: |ucker|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 23.77 Prob: 99.60% Token: |ucker|\n",
      "Top 1th token. Logit: 17.93 Prob:  0.29% Token: |uk|\n",
      "Top 2th token. Logit: 16.55 Prob:  0.07% Token: |uck|\n",
      "Top 3th token. Logit: 15.53 Prob:  0.03% Token: |uc|\n",
      "Top 4th token. Logit: 13.66 Prob:  0.00% Token: |UCK|\n",
      "Top 5th token. Logit: 12.91 Prob:  0.00% Token: |.|\n",
      "Top 6th token. Logit: 11.87 Prob:  0.00% Token: |ub|\n",
      "Top 7th token. Logit: 11.50 Prob:  0.00% Token: |ucks|\n",
      "Top 8th token. Logit: 11.00 Prob:  0.00% Token: |ander|\n",
      "Top 9th token. Logit: 10.94 Prob:  0.00% Token: |im|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.24</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.27</span><span style=\"font-weight: bold\">% Token: |berg|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m25.24\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m98.27\u001b[0m\u001b[1m% Token: |berg|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 25.24 Prob: 98.27% Token: |berg|\n",
      "Top 1th token. Logit: 21.15 Prob:  1.65% Token: |burg|\n",
      "Top 2th token. Logit: 17.57 Prob:  0.05% Token: |ber|\n",
      "Top 3th token. Logit: 16.38 Prob:  0.01% Token: |borg|\n",
      "Top 4th token. Logit: 15.81 Prob:  0.01% Token: |beg|\n",
      "Top 5th token. Logit: 13.86 Prob:  0.00% Token: |bert|\n",
      "Top 6th token. Logit: 13.72 Prob:  0.00% Token: |bur|\n",
      "Top 7th token. Logit: 13.15 Prob:  0.00% Token: |­|\n",
      "Top 8th token. Logit: 12.94 Prob:  0.00% Token: |b|\n",
      "Top 9th token. Logit: 12.89 Prob:  0.00% Token: |berger|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Z'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'ucker'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'berg'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Z'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'ucker'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'berg'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prompt Util -- Check the logit score of the expected output vs. the actual\n",
    "#                     output\n",
    "example_prompt = \"the founder of Facebook is Mark\"\n",
    "example_answer = \"Zuckerberg\"\n",
    "\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('embed.W_E', torch.Size([50280, 4096])),\n",
      " ('blocks.0.ln1.w', torch.Size([4096])),\n",
      " ('blocks.0.ln1.b', torch.Size([4096])),\n",
      " ('blocks.0.ln2.w', torch.Size([4096])),\n",
      " ('blocks.0.ln2.b', torch.Size([4096])),\n",
      " ('blocks.0.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.0.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.0.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.0.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.0.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.0.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.1.ln1.w', torch.Size([4096])),\n",
      " ('blocks.1.ln1.b', torch.Size([4096])),\n",
      " ('blocks.1.ln2.w', torch.Size([4096])),\n",
      " ('blocks.1.ln2.b', torch.Size([4096])),\n",
      " ('blocks.1.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.1.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.1.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.1.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.1.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.1.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.2.ln1.w', torch.Size([4096])),\n",
      " ('blocks.2.ln1.b', torch.Size([4096])),\n",
      " ('blocks.2.ln2.w', torch.Size([4096])),\n",
      " ('blocks.2.ln2.b', torch.Size([4096])),\n",
      " ('blocks.2.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.2.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.2.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.2.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.2.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.2.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.3.ln1.w', torch.Size([4096])),\n",
      " ('blocks.3.ln1.b', torch.Size([4096])),\n",
      " ('blocks.3.ln2.w', torch.Size([4096])),\n",
      " ('blocks.3.ln2.b', torch.Size([4096])),\n",
      " ('blocks.3.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.3.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.3.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.3.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.3.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.3.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.4.ln1.w', torch.Size([4096])),\n",
      " ('blocks.4.ln1.b', torch.Size([4096])),\n",
      " ('blocks.4.ln2.w', torch.Size([4096])),\n",
      " ('blocks.4.ln2.b', torch.Size([4096])),\n",
      " ('blocks.4.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.4.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.4.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.4.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.4.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.4.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.5.ln1.w', torch.Size([4096])),\n",
      " ('blocks.5.ln1.b', torch.Size([4096])),\n",
      " ('blocks.5.ln2.w', torch.Size([4096])),\n",
      " ('blocks.5.ln2.b', torch.Size([4096])),\n",
      " ('blocks.5.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.5.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.5.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.5.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.5.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.5.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.6.ln1.w', torch.Size([4096])),\n",
      " ('blocks.6.ln1.b', torch.Size([4096])),\n",
      " ('blocks.6.ln2.w', torch.Size([4096])),\n",
      " ('blocks.6.ln2.b', torch.Size([4096])),\n",
      " ('blocks.6.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.6.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.6.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.6.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.6.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.6.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.7.ln1.w', torch.Size([4096])),\n",
      " ('blocks.7.ln1.b', torch.Size([4096])),\n",
      " ('blocks.7.ln2.w', torch.Size([4096])),\n",
      " ('blocks.7.ln2.b', torch.Size([4096])),\n",
      " ('blocks.7.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.7.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.7.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.7.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.7.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.7.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.8.ln1.w', torch.Size([4096])),\n",
      " ('blocks.8.ln1.b', torch.Size([4096])),\n",
      " ('blocks.8.ln2.w', torch.Size([4096])),\n",
      " ('blocks.8.ln2.b', torch.Size([4096])),\n",
      " ('blocks.8.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.8.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.8.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.8.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.8.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.8.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.9.ln1.w', torch.Size([4096])),\n",
      " ('blocks.9.ln1.b', torch.Size([4096])),\n",
      " ('blocks.9.ln2.w', torch.Size([4096])),\n",
      " ('blocks.9.ln2.b', torch.Size([4096])),\n",
      " ('blocks.9.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.9.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.9.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.9.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.9.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.9.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.10.ln1.w', torch.Size([4096])),\n",
      " ('blocks.10.ln1.b', torch.Size([4096])),\n",
      " ('blocks.10.ln2.w', torch.Size([4096])),\n",
      " ('blocks.10.ln2.b', torch.Size([4096])),\n",
      " ('blocks.10.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.10.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.10.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.10.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.10.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.10.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.11.ln1.w', torch.Size([4096])),\n",
      " ('blocks.11.ln1.b', torch.Size([4096])),\n",
      " ('blocks.11.ln2.w', torch.Size([4096])),\n",
      " ('blocks.11.ln2.b', torch.Size([4096])),\n",
      " ('blocks.11.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.11.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.11.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.11.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.11.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.11.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.12.ln1.w', torch.Size([4096])),\n",
      " ('blocks.12.ln1.b', torch.Size([4096])),\n",
      " ('blocks.12.ln2.w', torch.Size([4096])),\n",
      " ('blocks.12.ln2.b', torch.Size([4096])),\n",
      " ('blocks.12.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.12.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.12.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.12.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.12.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.12.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.13.ln1.w', torch.Size([4096])),\n",
      " ('blocks.13.ln1.b', torch.Size([4096])),\n",
      " ('blocks.13.ln2.w', torch.Size([4096])),\n",
      " ('blocks.13.ln2.b', torch.Size([4096])),\n",
      " ('blocks.13.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.13.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.13.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.13.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.13.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.13.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.14.ln1.w', torch.Size([4096])),\n",
      " ('blocks.14.ln1.b', torch.Size([4096])),\n",
      " ('blocks.14.ln2.w', torch.Size([4096])),\n",
      " ('blocks.14.ln2.b', torch.Size([4096])),\n",
      " ('blocks.14.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.14.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.14.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.14.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.14.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.14.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.15.ln1.w', torch.Size([4096])),\n",
      " ('blocks.15.ln1.b', torch.Size([4096])),\n",
      " ('blocks.15.ln2.w', torch.Size([4096])),\n",
      " ('blocks.15.ln2.b', torch.Size([4096])),\n",
      " ('blocks.15.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.15.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.15.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.15.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.15.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.15.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.16.ln1.w', torch.Size([4096])),\n",
      " ('blocks.16.ln1.b', torch.Size([4096])),\n",
      " ('blocks.16.ln2.w', torch.Size([4096])),\n",
      " ('blocks.16.ln2.b', torch.Size([4096])),\n",
      " ('blocks.16.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.16.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.16.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.16.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.16.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.16.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.17.ln1.w', torch.Size([4096])),\n",
      " ('blocks.17.ln1.b', torch.Size([4096])),\n",
      " ('blocks.17.ln2.w', torch.Size([4096])),\n",
      " ('blocks.17.ln2.b', torch.Size([4096])),\n",
      " ('blocks.17.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.17.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.17.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.17.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.17.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.17.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.18.ln1.w', torch.Size([4096])),\n",
      " ('blocks.18.ln1.b', torch.Size([4096])),\n",
      " ('blocks.18.ln2.w', torch.Size([4096])),\n",
      " ('blocks.18.ln2.b', torch.Size([4096])),\n",
      " ('blocks.18.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.18.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.18.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.18.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.18.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.18.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.19.ln1.w', torch.Size([4096])),\n",
      " ('blocks.19.ln1.b', torch.Size([4096])),\n",
      " ('blocks.19.ln2.w', torch.Size([4096])),\n",
      " ('blocks.19.ln2.b', torch.Size([4096])),\n",
      " ('blocks.19.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.19.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.19.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.19.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.19.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.19.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.20.ln1.w', torch.Size([4096])),\n",
      " ('blocks.20.ln1.b', torch.Size([4096])),\n",
      " ('blocks.20.ln2.w', torch.Size([4096])),\n",
      " ('blocks.20.ln2.b', torch.Size([4096])),\n",
      " ('blocks.20.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.20.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.20.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.20.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.20.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.20.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.21.ln1.w', torch.Size([4096])),\n",
      " ('blocks.21.ln1.b', torch.Size([4096])),\n",
      " ('blocks.21.ln2.w', torch.Size([4096])),\n",
      " ('blocks.21.ln2.b', torch.Size([4096])),\n",
      " ('blocks.21.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.21.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.21.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.21.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.21.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.21.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.22.ln1.w', torch.Size([4096])),\n",
      " ('blocks.22.ln1.b', torch.Size([4096])),\n",
      " ('blocks.22.ln2.w', torch.Size([4096])),\n",
      " ('blocks.22.ln2.b', torch.Size([4096])),\n",
      " ('blocks.22.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.22.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.22.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.22.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.22.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.22.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.23.ln1.w', torch.Size([4096])),\n",
      " ('blocks.23.ln1.b', torch.Size([4096])),\n",
      " ('blocks.23.ln2.w', torch.Size([4096])),\n",
      " ('blocks.23.ln2.b', torch.Size([4096])),\n",
      " ('blocks.23.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.23.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.23.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.23.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.23.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.23.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.24.ln1.w', torch.Size([4096])),\n",
      " ('blocks.24.ln1.b', torch.Size([4096])),\n",
      " ('blocks.24.ln2.w', torch.Size([4096])),\n",
      " ('blocks.24.ln2.b', torch.Size([4096])),\n",
      " ('blocks.24.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.24.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.24.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.24.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.24.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.24.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.25.ln1.w', torch.Size([4096])),\n",
      " ('blocks.25.ln1.b', torch.Size([4096])),\n",
      " ('blocks.25.ln2.w', torch.Size([4096])),\n",
      " ('blocks.25.ln2.b', torch.Size([4096])),\n",
      " ('blocks.25.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.25.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.25.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.25.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.25.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.25.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.26.ln1.w', torch.Size([4096])),\n",
      " ('blocks.26.ln1.b', torch.Size([4096])),\n",
      " ('blocks.26.ln2.w', torch.Size([4096])),\n",
      " ('blocks.26.ln2.b', torch.Size([4096])),\n",
      " ('blocks.26.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.26.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.26.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.26.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.26.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.26.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.27.ln1.w', torch.Size([4096])),\n",
      " ('blocks.27.ln1.b', torch.Size([4096])),\n",
      " ('blocks.27.ln2.w', torch.Size([4096])),\n",
      " ('blocks.27.ln2.b', torch.Size([4096])),\n",
      " ('blocks.27.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.27.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.27.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.27.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.27.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.27.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.28.ln1.w', torch.Size([4096])),\n",
      " ('blocks.28.ln1.b', torch.Size([4096])),\n",
      " ('blocks.28.ln2.w', torch.Size([4096])),\n",
      " ('blocks.28.ln2.b', torch.Size([4096])),\n",
      " ('blocks.28.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.28.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.28.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.28.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.28.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.28.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.29.ln1.w', torch.Size([4096])),\n",
      " ('blocks.29.ln1.b', torch.Size([4096])),\n",
      " ('blocks.29.ln2.w', torch.Size([4096])),\n",
      " ('blocks.29.ln2.b', torch.Size([4096])),\n",
      " ('blocks.29.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.29.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.29.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.29.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.29.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.29.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.30.ln1.w', torch.Size([4096])),\n",
      " ('blocks.30.ln1.b', torch.Size([4096])),\n",
      " ('blocks.30.ln2.w', torch.Size([4096])),\n",
      " ('blocks.30.ln2.b', torch.Size([4096])),\n",
      " ('blocks.30.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.30.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.30.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.30.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.30.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.30.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.31.ln1.w', torch.Size([4096])),\n",
      " ('blocks.31.ln1.b', torch.Size([4096])),\n",
      " ('blocks.31.ln2.w', torch.Size([4096])),\n",
      " ('blocks.31.ln2.b', torch.Size([4096])),\n",
      " ('blocks.31.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.31.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.31.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.31.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.31.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.31.mlp.b_out', torch.Size([4096])),\n",
      " ('ln_final.w', torch.Size([4096])),\n",
      " ('ln_final.b', torch.Size([4096])),\n",
      " ('unembed.W_U', torch.Size([4096, 50280])),\n",
      " ('unembed.b_U', torch.Size([50280]))]\n"
     ]
    }
   ],
   "source": [
    "pprint([(name, param.shape) for name, param in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f5a95e472a4181b87ff8518dee7ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'abcdefghi\\n1234567890\\nabcdefghij\\n1234567890\\nabcdefghijk\\n1234567890\\nabcdefghijkl\\n1234567890\\nabcdefghijklm\\n1234567890\\nabcdefghijklmn\\n1234567890\\nabcdefghijklmno\\n1234567890\\nabcdefghijklmnop\\n1234567890\\nabcdefghik\\n01234567891\\nabcdefghikj\\n01234567892\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing out Dolly's Q/A ability.\n",
    "\n",
    "model.generate(\n",
    "    \"abcdefghi\",\n",
    "\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "# This Dolly is kind of dumb.\n",
    "# We should try to get A100 x 8 Cluster ASAP and get a full sized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct Logit Attribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
