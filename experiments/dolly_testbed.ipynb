{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment: Working with Dolly\n",
    "## Last Updated $DATE -  $AUTHOR.\n",
    "\n",
    "```\n",
    "Summary of High Level Research Question\n",
    "```\n",
    "\n",
    "Try to scope your experiments such you can answer your research question in 1-3 hours.\n",
    "This is an ideal time block to enter flow / deep work, but short enough that you will still feel \n",
    "motivated by a relatively tight feedback loop.\n",
    "\n",
    "If a problem seems like it needs more time that that, \n",
    "\n",
    "### High Level Experiment Design\n",
    "\n",
    "## Goals:\n",
    "```\n",
    "List of specific goals that this experiment seeks to achieve.\n",
    "\n",
    "This should fall under a few categories:\n",
    "- Development of Intuition about a _specific_ topic\n",
    "- Novel Research or Insight that could lead to a publishable result\n",
    "- Meaningfully explore a topic which could lead to an improvement in product\n",
    "\n",
    "Guiding principles should understanding, insight, and value creation.\n",
    "```\n",
    "\n",
    "## Tasks & Experiment Design\n",
    "\n",
    "```\n",
    "A list of specific tasks that are going to be tested \n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "## Outcomes\n",
    "\n",
    "```\n",
    "Document high level research findings and how\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/neelnanda-io/TransformerLens.git\n",
      "  Cloning https://github.com/neelnanda-io/TransformerLens.git to /tmp/pip-req-build-6s167ycj\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/neelnanda-io/TransformerLens.git /tmp/pip-req-build-6s167ycj\n",
      "  Resolved https://github.com/neelnanda-io/TransformerLens.git to commit 0ffcc8ad647d9e991f4c2596557a9d7475617773\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.64.1 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (4.64.1)\n",
      "Collecting datasets>=2.7.1\n",
      "  Downloading datasets-2.12.0-py3-none-any.whl (474 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting wandb>=0.13.5\n",
      "  Downloading wandb-0.15.1-py3-none-any.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting fancy-einsum>=0.0.3\n",
      "  Downloading fancy_einsum-0.0.3-py3-none-any.whl (6.2 kB)\n",
      "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.5.0)\n",
      "Collecting einops>=0.6.0\n",
      "  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting jaxtyping>=0.2.11\n",
      "  Downloading jaxtyping-0.2.15-py3-none-any.whl (20 kB)\n",
      "Requirement already satisfied: rich>=12.6.0 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (13.2.0)\n",
      "Collecting transformers>=4.25.1\n",
      "  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch>=1.10 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.9/dist-packages (from transformer-lens==0.0.0) (1.23.4)\n",
      "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.18.0)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2023.1.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (5.4.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (2.28.2)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (3.2.0)\n",
      "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.70.13)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.3.5.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (0.12.0)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (23.0)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets>=2.7.1->transformer-lens==0.0.0) (10.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.9/dist-packages (from jaxtyping>=0.2.11->transformer-lens==0.0.0) (4.4.0)\n",
      "Collecting typeguard>=2.13.3\n",
      "  Downloading typeguard-3.0.2-py3-none-any.whl (30 kB)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2022.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.9/dist-packages (from pandas>=1.1.5->transformer-lens==0.0.0) (2.8.2)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.1.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.6.0 in /usr/local/lib/python3.9/dist-packages (from rich>=12.6.0->transformer-lens==0.0.0) (2.14.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (2022.10.31)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (3.9.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.9/dist-packages (from transformers>=4.25.1->transformer-lens==0.0.0) (0.12.1)\n",
      "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.1.30)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.4.0)\n",
      "Collecting appdirs>=1.4.3\n",
      "  Downloading appdirs-1.4.4-py2.py3-none-any.whl (9.6 kB)\n",
      "Requirement already satisfied: pathtools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.3.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.15.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (3.19.6)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (66.1.1)\n",
      "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (8.1.3)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (5.9.4)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /usr/lib/python3/dist-packages (from docker-pycreds>=0.4.0->wandb>=0.13.5->transformer-lens==0.0.0) (1.14.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (6.0.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.3.3)\n",
      "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (2.1.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (18.2.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (1.8.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets>=2.7.1->transformer-lens==0.0.0) (4.0.2)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.9/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (4.0.10)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.9/dist-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=12.6.0->transformer-lens==0.0.0) (0.1.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.19.0->datasets>=2.7.1->transformer-lens==0.0.0) (1.26.14)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.9/dist-packages (from typeguard>=2.13.3->jaxtyping>=0.2.11->transformer-lens==0.0.0) (6.0.0)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.9/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb>=0.13.5->transformer-lens==0.0.0) (5.0.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=3.6->typeguard>=2.13.3->jaxtyping>=0.2.11->transformer-lens==0.0.0) (3.11.0)\n",
      "Building wheels for collected packages: transformer-lens\n",
      "  Building wheel for transformer-lens (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for transformer-lens: filename=transformer_lens-0.0.0-py3-none-any.whl size=89099 sha256=e9c4c1a436abe06007462feb506e9c233fd924e1ed72f98b6e58c637a50413aa\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-papaxbfv/wheels/5f/16/e5/d9e9cc7a92784f4ab1b78c482598b8cc3ffed2b3eefe88045f\n",
      "Successfully built transformer-lens\n",
      "Installing collected packages: appdirs, fancy-einsum, einops, typeguard, wandb, transformers, jaxtyping, datasets, transformer-lens\n",
      "  Attempting uninstall: wandb\n",
      "    Found existing installation: wandb 0.13.4\n",
      "    Uninstalling wandb-0.13.4:\n",
      "      Successfully uninstalled wandb-0.13.4\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.21.3\n",
      "    Uninstalling transformers-4.21.3:\n",
      "      Successfully uninstalled transformers-4.21.3\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.4.0\n",
      "    Uninstalling datasets-2.4.0:\n",
      "      Successfully uninstalled datasets-2.4.0\n",
      "Successfully installed appdirs-1.4.4 datasets-2.12.0 einops-0.6.1 fancy-einsum-0.0.3 jaxtyping-0.2.15 transformer-lens-0.0.0 transformers-4.28.1 typeguard-3.0.2 wandb-0.15.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting circuitsvis\n",
      "  Downloading circuitsvis-1.39.1-py3-none-any.whl (1.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<2.0,>=1.10 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.12.1+cu116)\n",
      "Requirement already satisfied: numpy<2.0,>=1.21 in /usr/local/lib/python3.9/dist-packages (from circuitsvis) (1.23.4)\n",
      "Collecting importlib-metadata<6.0.0,>=5.1.0\n",
      "  Downloading importlib_metadata-5.2.0-py3-none-any.whl (21 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata<6.0.0,>=5.1.0->circuitsvis) (3.11.0)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch<2.0,>=1.10->circuitsvis) (4.4.0)\n",
      "Installing collected packages: importlib-metadata, circuitsvis\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 6.0.0\n",
      "    Uninstalling importlib-metadata-6.0.0:\n",
      "      Successfully uninstalled importlib-metadata-6.0.0\n",
      "Successfully installed circuitsvis-1.39.1 importlib-metadata-5.2.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting plotly\n",
      "  Downloading plotly-5.14.1-py2.py3-none-any.whl (15.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/15.3 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from plotly) (23.0)\n",
      "Collecting tenacity>=6.2.0\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: tenacity, plotly\n",
      "Successfully installed plotly-5.14.1 tenacity-8.2.2\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install things into ENV\n",
    "# TODO: Setup up a container and push to docker that contains all these\n",
    "%pip install git+https://github.com/neelnanda-io/TransformerLens.git\n",
    "%pip install circuitsvis\n",
    "%pip install plotly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Generic Set of Imports for MI Research\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import einops\n",
    "from fancy_einsum import einsum\n",
    "import tqdm.auto as tqdm\n",
    "import random\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "import plotly.express as px\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from jaxtyping import Float, Int\n",
    "from typing import List, Union, Optional\n",
    "from functools import partial\n",
    "import copy\n",
    "\n",
    "import itertools\n",
    "from transformers import AutoModelForCausalLM, AutoConfig, AutoTokenizer\n",
    "import dataclasses\n",
    "import datasets\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import transformer_lens\n",
    "import transformer_lens.utils as utils\n",
    "from transformer_lens.hook_points import (\n",
    "    HookedRootModule,\n",
    "    HookPoint,\n",
    ")  # Hooking utilities\n",
    "from transformer_lens import HookedTransformer, HookedTransformerConfig, FactoredMatrix, ActivationCache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "# Setup PyTorch configuration for inference based experiments\n",
    "# NOTE: Mark as False if you want to do any kind of training \n",
    "#       as part of your experimentation\n",
    "\n",
    "INFERENCE_ONLY_EXPERIMENT = True\n",
    "if INFERENCE_ONLY_EXPERIMENT:\n",
    "    torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)\n",
    "\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook_connected\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def imshow(tensor, renderer=None, **kwargs):\n",
    "    px.imshow(utils.to_numpy(tensor), color_continuous_midpoint=0.0, color_continuous_scale=\"RdBu\", **kwargs).show(renderer)\n",
    "\n",
    "def line(tensor, renderer=None, **kwargs):\n",
    "    px.line(y=utils.to_numpy(tensor), **kwargs).show(renderer)\n",
    "\n",
    "def scatter(x, y, xaxis=\"\", yaxis=\"\", caxis=\"\", renderer=None, **kwargs):\n",
    "    x = utils.to_numpy(x)\n",
    "    y = utils.to_numpy(y)\n",
    "    px.scatter(y=y, x=x, labels={\"x\":xaxis, \"y\":yaxis, \"color\":caxis}, **kwargs).show(renderer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div id=\"circuits-vis-5741f016-0de4\" style=\"margin: 15px 0;\"/>\n",
       "    <script crossorigin type=\"module\">\n",
       "    import { render, Hello } from \"https://unpkg.com/circuitsvis@1.39.1/dist/cdn/esm.js\";\n",
       "    render(\n",
       "      \"circuits-vis-5741f016-0de4\",\n",
       "      Hello,\n",
       "      {\"name\": \"Vivek\"}\n",
       "    )\n",
       "    </script>"
      ],
      "text/plain": [
       "<circuitsvis.utils.render.RenderedHTML at 0x7f227f193220>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Circuit Visualizations\n",
    "# TODO: Explore building out our own packages / tooling\n",
    "import circuitsvis as cv\n",
    "# Testing that the library works\n",
    "cv.examples.hello(\"Vivek\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df983bde79c437fa4240fac6a2b65a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/450 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24c34c0d2e9e46388a63cf9a16fd78cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/2.11M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b98c9e81cec74b298a1700dc5ee7b0f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/228 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4022b1047b0a4e7585a41b9f4eda85ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/819 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec928e0a42245268d02348b930ca863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/13.8G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load & Run a Model\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"databricks/dolly-v2-7b\")\n",
    "hf_model = AutoModelForCausalLM.from_pretrained(\"databricks/dolly-v2-7b\")\n",
    "\n",
    "print(\"Loaded hf_model, hooking transformer into TransformerLens!\")\n",
    "# model = HookedTransformer.from_pretrained(\n",
    "#     \"EleutherAI/pythia-6.9b-deduped\",\n",
    "#     center_unembed=False,\n",
    "#     center_writing_weights=False,\n",
    "#     fold_ln=False,\n",
    "#     refactor_factored_attn_matrices=True,\n",
    "#     hf_model=hf_model\n",
    "# )\n",
    "\n",
    "### Janky Shit\n",
    "### TODO: Figure out how this library actually works and make this a cleaner integration.\n",
    "import transformer_lens.loading_from_pretrained as loading\n",
    "# Get the model name used in HuggingFace, rather than the alias.\n",
    "official_model_name = loading.get_official_model_name(\"EleutherAI/pythia-6.9b-deduped\")\n",
    "\n",
    "\n",
    "# Load the config into an HookedTransformerConfig object. If loading from a\n",
    "# checkpoint, the config object will contain the information about the\n",
    "# checkpoint\n",
    "cfg = loading.get_pretrained_model_config(\n",
    "    official_model_name,\n",
    "    checkpoint_index=None,\n",
    "    checkpoint_value=None,\n",
    "    fold_ln=False,\n",
    "    device=device,\n",
    "    n_devices=1,\n",
    ")\n",
    "print(cfg)\n",
    "cfg.d_vocab = 50280\n",
    "cfg.d_vocab_out = 50280\n",
    "print(cfg)\n",
    "\n",
    "\n",
    "# Get the state dict of the model (ie a mapping of parameter names to tensors), processed to match the HookedTransformer parameter names.\n",
    "state_dict = loading.get_pretrained_state_dict(\n",
    "    official_model_name, cfg, hf_model\n",
    ")\n",
    "\n",
    "# Create the HookedTransformer object\n",
    "model = HookedTransformer(cfg, tokenizer=tokenizer)\n",
    "\n",
    "model.load_and_process_state_dict(\n",
    "    state_dict,\n",
    "    fold_ln=False,\n",
    "    center_writing_weights=False,\n",
    "    center_unembed=False,\n",
    "    refactor_factored_attn_matrices=False,\n",
    "    move_state_dict_to_device=True,\n",
    ")\n",
    "\n",
    "print(f\"Loaded pretrained model into HookedTransformer!\")\n",
    "\n",
    "model_description_text = \"\"\"For this demo notebook we'll look at Dolly v2. It is based on pythia 6.9b, but we use the weights for dolly v2. To try the model the model out, let's find the loss on this paragraph!\"\"\"\n",
    "# return_type of model can be loss, logits, both, or none!\n",
    "loss = model(model_description_text, return_type=\"loss\")\n",
    "print(\"Model loss:\", loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# DOLLY V2 - 7B Config\n",
    "pprint(model.cfg)\n",
    "\n",
    "# Transformer Lens Note:\n",
    "# get_token_position, to_tokens, to_string, to_str_tokens, prepend_bos, to_single_token\n",
    "# are all methods that are added to the model object by TransformerLens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|endoftext|>', 'On', ' hall', 'ow', 'een', ',', ' all', ' the', ' children', ' go', ' T', 'rick', ' or']\n",
      "tensor([[   0, 2374, 7423,  319, 9673,   13,  512,  253, 2151,  564,  308, 4662,\n",
      "          390]], device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1428353e3824eef84f7d6d1b3fdc42e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'On halloween, all the children go Trick or Treat'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_string = \"On halloween, all the children go Trick or\"\n",
    "\n",
    "print(model.to_str_tokens(sample_string)) # Shows tokenization split\n",
    "print(model.to_tokens(sample_string)) #converts string to integer labeled tokens and then returns a tensor on models device of shape (batch, position)\n",
    "# NOTE: in GPT2, 50256 is the token for EOS, BOS, and Padding.\n",
    "# To single token converts string to a single integer, useful for looking up logits\n",
    "# to_string converts a tensor of tokens to a string\n",
    "\n",
    "\n",
    "model.generate(sample_string, \n",
    "               temperature=0,\n",
    "               max_new_tokens=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized prompt: ['<|endoftext|>', 'the', ' founder', ' of', ' Facebook', ' is', ' Mark']\n",
      "Tokenized answer: [' Z', 'ucker', 'berg']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22.91</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.94</span><span style=\"font-weight: bold\">% Token: | Z|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m22.91\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m99.94\u001b[0m\u001b[1m% Token: | Z|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 22.91 Prob: 99.94% Token: | Z|\n",
      "Top 1th token. Logit: 15.02 Prob:  0.04% Token: | z|\n",
      "Top 2th token. Logit: 12.46 Prob:  0.00% Token: | E|\n",
      "Top 3th token. Logit: 12.16 Prob:  0.00% Token: | Elliot|\n",
      "Top 4th token. Logit: 11.97 Prob:  0.00% Token: |\n",
      "|\n",
      "Top 5th token. Logit: 11.81 Prob:  0.00% Token: | Cuban|\n",
      "Top 6th token. Logit: 11.52 Prob:  0.00% Token: |Z|\n",
      "Top 7th token. Logit: 11.40 Prob:  0.00% Token: |  |\n",
      "Top 8th token. Logit: 10.68 Prob:  0.00% Token: |us|\n",
      "Top 9th token. Logit: 10.56 Prob:  0.00% Token: |.|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23.77</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">99.60</span><span style=\"font-weight: bold\">% Token: |ucker|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m23.77\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m99.60\u001b[0m\u001b[1m% Token: |ucker|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 23.77 Prob: 99.60% Token: |ucker|\n",
      "Top 1th token. Logit: 17.93 Prob:  0.29% Token: |uk|\n",
      "Top 2th token. Logit: 16.55 Prob:  0.07% Token: |uck|\n",
      "Top 3th token. Logit: 15.53 Prob:  0.03% Token: |uc|\n",
      "Top 4th token. Logit: 13.66 Prob:  0.00% Token: |UCK|\n",
      "Top 5th token. Logit: 12.91 Prob:  0.00% Token: |.|\n",
      "Top 6th token. Logit: 11.87 Prob:  0.00% Token: |ub|\n",
      "Top 7th token. Logit: 11.50 Prob:  0.00% Token: |ucks|\n",
      "Top 8th token. Logit: 11.00 Prob:  0.00% Token: |ander|\n",
      "Top 9th token. Logit: 10.94 Prob:  0.00% Token: |im|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Performance on answer token:\n",
       "<span style=\"font-weight: bold\">Rank: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">        Logit: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25.24</span><span style=\"font-weight: bold\"> Prob: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">98.27</span><span style=\"font-weight: bold\">% Token: |berg|</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Performance on answer token:\n",
       "\u001b[1mRank: \u001b[0m\u001b[1;36m0\u001b[0m\u001b[1m        Logit: \u001b[0m\u001b[1;36m25.24\u001b[0m\u001b[1m Prob: \u001b[0m\u001b[1;36m98.27\u001b[0m\u001b[1m% Token: |berg|\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 0th token. Logit: 25.24 Prob: 98.27% Token: |berg|\n",
      "Top 1th token. Logit: 21.15 Prob:  1.65% Token: |burg|\n",
      "Top 2th token. Logit: 17.57 Prob:  0.05% Token: |ber|\n",
      "Top 3th token. Logit: 16.38 Prob:  0.01% Token: |borg|\n",
      "Top 4th token. Logit: 15.81 Prob:  0.01% Token: |beg|\n",
      "Top 5th token. Logit: 13.86 Prob:  0.00% Token: |bert|\n",
      "Top 6th token. Logit: 13.72 Prob:  0.00% Token: |bur|\n",
      "Top 7th token. Logit: 13.15 Prob:  0.00% Token: |­|\n",
      "Top 8th token. Logit: 12.94 Prob:  0.00% Token: |b|\n",
      "Top 9th token. Logit: 12.89 Prob:  0.00% Token: |berger|\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Ranks of the answer tokens:</span> <span style=\"font-weight: bold\">[(</span><span style=\"color: #008000; text-decoration-color: #008000\">' Z'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'ucker'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)</span>, <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'berg'</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"font-weight: bold\">)]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mRanks of the answer tokens:\u001b[0m \u001b[1m[\u001b[0m\u001b[1m(\u001b[0m\u001b[32m' Z'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'ucker'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m, \u001b[1m(\u001b[0m\u001b[32m'berg'\u001b[0m, \u001b[1;36m0\u001b[0m\u001b[1m)\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test Prompt Util -- Check the logit score of the expected output vs. the actual\n",
    "#                     output\n",
    "example_prompt = \"the founder of Facebook is Mark\"\n",
    "example_answer = \"Zuckerberg\"\n",
    "\n",
    "utils.test_prompt(example_prompt, example_answer, model, prepend_bos=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('embed.W_E', torch.Size([50280, 4096])),\n",
      " ('blocks.0.ln1.w', torch.Size([4096])),\n",
      " ('blocks.0.ln1.b', torch.Size([4096])),\n",
      " ('blocks.0.ln2.w', torch.Size([4096])),\n",
      " ('blocks.0.ln2.b', torch.Size([4096])),\n",
      " ('blocks.0.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.0.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.0.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.0.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.0.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.0.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.0.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.0.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.1.ln1.w', torch.Size([4096])),\n",
      " ('blocks.1.ln1.b', torch.Size([4096])),\n",
      " ('blocks.1.ln2.w', torch.Size([4096])),\n",
      " ('blocks.1.ln2.b', torch.Size([4096])),\n",
      " ('blocks.1.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.1.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.1.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.1.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.1.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.1.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.1.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.1.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.2.ln1.w', torch.Size([4096])),\n",
      " ('blocks.2.ln1.b', torch.Size([4096])),\n",
      " ('blocks.2.ln2.w', torch.Size([4096])),\n",
      " ('blocks.2.ln2.b', torch.Size([4096])),\n",
      " ('blocks.2.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.2.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.2.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.2.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.2.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.2.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.2.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.2.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.3.ln1.w', torch.Size([4096])),\n",
      " ('blocks.3.ln1.b', torch.Size([4096])),\n",
      " ('blocks.3.ln2.w', torch.Size([4096])),\n",
      " ('blocks.3.ln2.b', torch.Size([4096])),\n",
      " ('blocks.3.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.3.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.3.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.3.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.3.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.3.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.3.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.3.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.4.ln1.w', torch.Size([4096])),\n",
      " ('blocks.4.ln1.b', torch.Size([4096])),\n",
      " ('blocks.4.ln2.w', torch.Size([4096])),\n",
      " ('blocks.4.ln2.b', torch.Size([4096])),\n",
      " ('blocks.4.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.4.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.4.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.4.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.4.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.4.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.4.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.4.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.5.ln1.w', torch.Size([4096])),\n",
      " ('blocks.5.ln1.b', torch.Size([4096])),\n",
      " ('blocks.5.ln2.w', torch.Size([4096])),\n",
      " ('blocks.5.ln2.b', torch.Size([4096])),\n",
      " ('blocks.5.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.5.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.5.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.5.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.5.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.5.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.5.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.5.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.6.ln1.w', torch.Size([4096])),\n",
      " ('blocks.6.ln1.b', torch.Size([4096])),\n",
      " ('blocks.6.ln2.w', torch.Size([4096])),\n",
      " ('blocks.6.ln2.b', torch.Size([4096])),\n",
      " ('blocks.6.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.6.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.6.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.6.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.6.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.6.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.6.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.6.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.7.ln1.w', torch.Size([4096])),\n",
      " ('blocks.7.ln1.b', torch.Size([4096])),\n",
      " ('blocks.7.ln2.w', torch.Size([4096])),\n",
      " ('blocks.7.ln2.b', torch.Size([4096])),\n",
      " ('blocks.7.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.7.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.7.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.7.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.7.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.7.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.7.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.7.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.8.ln1.w', torch.Size([4096])),\n",
      " ('blocks.8.ln1.b', torch.Size([4096])),\n",
      " ('blocks.8.ln2.w', torch.Size([4096])),\n",
      " ('blocks.8.ln2.b', torch.Size([4096])),\n",
      " ('blocks.8.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.8.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.8.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.8.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.8.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.8.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.8.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.8.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.9.ln1.w', torch.Size([4096])),\n",
      " ('blocks.9.ln1.b', torch.Size([4096])),\n",
      " ('blocks.9.ln2.w', torch.Size([4096])),\n",
      " ('blocks.9.ln2.b', torch.Size([4096])),\n",
      " ('blocks.9.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.9.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.9.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.9.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.9.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.9.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.9.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.9.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.10.ln1.w', torch.Size([4096])),\n",
      " ('blocks.10.ln1.b', torch.Size([4096])),\n",
      " ('blocks.10.ln2.w', torch.Size([4096])),\n",
      " ('blocks.10.ln2.b', torch.Size([4096])),\n",
      " ('blocks.10.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.10.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.10.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.10.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.10.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.10.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.10.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.10.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.11.ln1.w', torch.Size([4096])),\n",
      " ('blocks.11.ln1.b', torch.Size([4096])),\n",
      " ('blocks.11.ln2.w', torch.Size([4096])),\n",
      " ('blocks.11.ln2.b', torch.Size([4096])),\n",
      " ('blocks.11.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.11.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.11.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.11.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.11.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.11.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.11.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.11.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.12.ln1.w', torch.Size([4096])),\n",
      " ('blocks.12.ln1.b', torch.Size([4096])),\n",
      " ('blocks.12.ln2.w', torch.Size([4096])),\n",
      " ('blocks.12.ln2.b', torch.Size([4096])),\n",
      " ('blocks.12.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.12.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.12.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.12.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.12.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.12.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.12.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.12.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.13.ln1.w', torch.Size([4096])),\n",
      " ('blocks.13.ln1.b', torch.Size([4096])),\n",
      " ('blocks.13.ln2.w', torch.Size([4096])),\n",
      " ('blocks.13.ln2.b', torch.Size([4096])),\n",
      " ('blocks.13.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.13.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.13.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.13.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.13.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.13.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.13.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.13.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.14.ln1.w', torch.Size([4096])),\n",
      " ('blocks.14.ln1.b', torch.Size([4096])),\n",
      " ('blocks.14.ln2.w', torch.Size([4096])),\n",
      " ('blocks.14.ln2.b', torch.Size([4096])),\n",
      " ('blocks.14.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.14.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.14.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.14.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.14.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.14.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.14.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.14.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.15.ln1.w', torch.Size([4096])),\n",
      " ('blocks.15.ln1.b', torch.Size([4096])),\n",
      " ('blocks.15.ln2.w', torch.Size([4096])),\n",
      " ('blocks.15.ln2.b', torch.Size([4096])),\n",
      " ('blocks.15.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.15.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.15.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.15.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.15.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.15.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.15.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.15.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.16.ln1.w', torch.Size([4096])),\n",
      " ('blocks.16.ln1.b', torch.Size([4096])),\n",
      " ('blocks.16.ln2.w', torch.Size([4096])),\n",
      " ('blocks.16.ln2.b', torch.Size([4096])),\n",
      " ('blocks.16.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.16.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.16.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.16.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.16.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.16.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.16.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.16.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.17.ln1.w', torch.Size([4096])),\n",
      " ('blocks.17.ln1.b', torch.Size([4096])),\n",
      " ('blocks.17.ln2.w', torch.Size([4096])),\n",
      " ('blocks.17.ln2.b', torch.Size([4096])),\n",
      " ('blocks.17.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.17.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.17.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.17.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.17.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.17.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.17.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.17.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.18.ln1.w', torch.Size([4096])),\n",
      " ('blocks.18.ln1.b', torch.Size([4096])),\n",
      " ('blocks.18.ln2.w', torch.Size([4096])),\n",
      " ('blocks.18.ln2.b', torch.Size([4096])),\n",
      " ('blocks.18.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.18.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.18.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.18.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.18.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.18.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.18.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.18.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.19.ln1.w', torch.Size([4096])),\n",
      " ('blocks.19.ln1.b', torch.Size([4096])),\n",
      " ('blocks.19.ln2.w', torch.Size([4096])),\n",
      " ('blocks.19.ln2.b', torch.Size([4096])),\n",
      " ('blocks.19.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.19.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.19.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.19.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.19.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.19.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.19.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.19.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.20.ln1.w', torch.Size([4096])),\n",
      " ('blocks.20.ln1.b', torch.Size([4096])),\n",
      " ('blocks.20.ln2.w', torch.Size([4096])),\n",
      " ('blocks.20.ln2.b', torch.Size([4096])),\n",
      " ('blocks.20.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.20.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.20.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.20.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.20.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.20.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.20.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.20.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.21.ln1.w', torch.Size([4096])),\n",
      " ('blocks.21.ln1.b', torch.Size([4096])),\n",
      " ('blocks.21.ln2.w', torch.Size([4096])),\n",
      " ('blocks.21.ln2.b', torch.Size([4096])),\n",
      " ('blocks.21.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.21.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.21.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.21.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.21.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.21.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.21.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.21.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.22.ln1.w', torch.Size([4096])),\n",
      " ('blocks.22.ln1.b', torch.Size([4096])),\n",
      " ('blocks.22.ln2.w', torch.Size([4096])),\n",
      " ('blocks.22.ln2.b', torch.Size([4096])),\n",
      " ('blocks.22.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.22.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.22.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.22.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.22.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.22.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.22.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.22.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.23.ln1.w', torch.Size([4096])),\n",
      " ('blocks.23.ln1.b', torch.Size([4096])),\n",
      " ('blocks.23.ln2.w', torch.Size([4096])),\n",
      " ('blocks.23.ln2.b', torch.Size([4096])),\n",
      " ('blocks.23.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.23.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.23.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.23.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.23.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.23.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.23.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.23.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.24.ln1.w', torch.Size([4096])),\n",
      " ('blocks.24.ln1.b', torch.Size([4096])),\n",
      " ('blocks.24.ln2.w', torch.Size([4096])),\n",
      " ('blocks.24.ln2.b', torch.Size([4096])),\n",
      " ('blocks.24.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.24.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.24.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.24.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.24.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.24.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.24.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.24.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.25.ln1.w', torch.Size([4096])),\n",
      " ('blocks.25.ln1.b', torch.Size([4096])),\n",
      " ('blocks.25.ln2.w', torch.Size([4096])),\n",
      " ('blocks.25.ln2.b', torch.Size([4096])),\n",
      " ('blocks.25.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.25.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.25.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.25.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.25.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.25.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.25.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.25.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.26.ln1.w', torch.Size([4096])),\n",
      " ('blocks.26.ln1.b', torch.Size([4096])),\n",
      " ('blocks.26.ln2.w', torch.Size([4096])),\n",
      " ('blocks.26.ln2.b', torch.Size([4096])),\n",
      " ('blocks.26.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.26.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.26.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.26.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.26.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.26.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.26.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.26.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.27.ln1.w', torch.Size([4096])),\n",
      " ('blocks.27.ln1.b', torch.Size([4096])),\n",
      " ('blocks.27.ln2.w', torch.Size([4096])),\n",
      " ('blocks.27.ln2.b', torch.Size([4096])),\n",
      " ('blocks.27.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.27.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.27.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.27.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.27.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.27.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.27.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.27.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.28.ln1.w', torch.Size([4096])),\n",
      " ('blocks.28.ln1.b', torch.Size([4096])),\n",
      " ('blocks.28.ln2.w', torch.Size([4096])),\n",
      " ('blocks.28.ln2.b', torch.Size([4096])),\n",
      " ('blocks.28.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.28.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.28.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.28.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.28.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.28.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.28.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.28.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.29.ln1.w', torch.Size([4096])),\n",
      " ('blocks.29.ln1.b', torch.Size([4096])),\n",
      " ('blocks.29.ln2.w', torch.Size([4096])),\n",
      " ('blocks.29.ln2.b', torch.Size([4096])),\n",
      " ('blocks.29.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.29.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.29.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.29.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.29.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.29.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.29.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.29.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.30.ln1.w', torch.Size([4096])),\n",
      " ('blocks.30.ln1.b', torch.Size([4096])),\n",
      " ('blocks.30.ln2.w', torch.Size([4096])),\n",
      " ('blocks.30.ln2.b', torch.Size([4096])),\n",
      " ('blocks.30.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.30.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.30.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.30.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.30.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.30.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.30.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.30.mlp.b_out', torch.Size([4096])),\n",
      " ('blocks.31.ln1.w', torch.Size([4096])),\n",
      " ('blocks.31.ln1.b', torch.Size([4096])),\n",
      " ('blocks.31.ln2.w', torch.Size([4096])),\n",
      " ('blocks.31.ln2.b', torch.Size([4096])),\n",
      " ('blocks.31.attn.W_Q', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_K', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_V', torch.Size([32, 4096, 128])),\n",
      " ('blocks.31.attn.W_O', torch.Size([32, 128, 4096])),\n",
      " ('blocks.31.attn.b_Q', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_K', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_V', torch.Size([32, 128])),\n",
      " ('blocks.31.attn.b_O', torch.Size([4096])),\n",
      " ('blocks.31.mlp.W_in', torch.Size([4096, 16384])),\n",
      " ('blocks.31.mlp.b_in', torch.Size([16384])),\n",
      " ('blocks.31.mlp.W_out', torch.Size([16384, 4096])),\n",
      " ('blocks.31.mlp.b_out', torch.Size([4096])),\n",
      " ('ln_final.w', torch.Size([4096])),\n",
      " ('ln_final.b', torch.Size([4096])),\n",
      " ('unembed.W_U', torch.Size([4096, 50280])),\n",
      " ('unembed.b_U', torch.Size([50280]))]\n"
     ]
    }
   ],
   "source": [
    "pprint([(name, param.shape) for name, param in model.named_parameters()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc65c31fd9ce4538b8cf0d9cafb26017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Can you write a short story about a unicorn? (covers description, esc in the story)\\n\\nFifteen-year-old Lauren wanted a unicorn pronto. She loved the beautiful creatures and keep seeing them everywhere. She saw one on a dinner plate at her friend Claire’s house and on a mobile phone case at her friend Claire’s house. She was disappointed when Claire told her that they weren’t real. Claire told her that they were a marketing gimmick from a toy commercial. Lauren believed Claire. She'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing out Dolly's Q/A ability.\n",
    "\n",
    "model.generate(\n",
    "    \"Can you write a short story about a unicorn?\",\n",
    "    max_new_tokens=100,\n",
    ")\n",
    "\n",
    "# This Dolly is kind of dumb.\n",
    "# We should try to get A100 x 8 Cluster ASAP and get a full sized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "# Direct Logit Attribution\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
